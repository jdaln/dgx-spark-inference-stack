# Model Selection Guide

Choose the right model for your task to balance performance and speed.

> [!WARNING]
> This document is **100% AI generated** and might need improvements.

## Quick chooser (what to use for what)

### âœ… Best default chat / general assistant
- **`gpt-oss-20b`** â†’ fast + strong quality for most tasks
- **`gpt-oss-120b`** â†’ best overall quality when latency/cost is okay
- **`glm-4.5-air-fp4`** â†’ great general assistant alternative (often â€œagent-yâ€)


### ğŸ§  Heavy reasoning (math, logic, planning, step-by-step)
- **`qwen3-next-80b-a3b-thinking-fp4`** â†’ fast MoE â€œthinkingâ€ model (high throughput)
- **`deepseek-r1-distill-qwen-32b`** â†’ very strong reasoning per GPU
- **`phi-4-reasoning-plus-fp4`** â†’ careful/robust reasoning style
- **`nemotron-3-nano-30b-fp8`** â†’ efficient MoE reasoning + long-context workloads

### ğŸ’» Coding / repo edits / tool-assisted programming
- **`qwen3-coder-30b-a3b-instruct`** â†’ long-context coding + tool usage
- **`qwen2.5-coder-7b-instruct`** â†’ budget coding assistant

### ğŸ‘ï¸ Vision (screenshots, UI, diagrams, â€œlook at this imageâ€)
- **`qwen3-vl-32b-instruct-fp4`** â†’ best quality VL for docs + screenshots
- **`qwen3-vl-30b-instruct`** â†’ new Qwen3 Vision-Language model

- **`glm-4.6v-flash-fp4`** â†’ fastest VL for real-time UI workflows
- **`phi-4-multimodal-instruct-fp4`** â†’ solid â€œone model for text+image(+audio)â€
- **`qwen2.5-vl-7b`** â†’ cheapest practical VL

### ğŸ” OCR (image â†’ raw text extraction)
- **`deepseek-ocr`** â†’ best when you need clean extracted text

### ğŸ§ Audio
- **`step-audio-r1-fp4`** â†’ audio understanding + reasoning (Disabled)

### ğŸŒ EU languages / multilingual support
- **`eurollm-22b-instruct-fp4`** â†’ EU-language focused assistant

### ğŸª¶ Small â€œutility modelâ€
- **`qwen2.5-1.5b-instruct`** â†’ classification, formatting, tagging, structured output, session titles

---

## Model Details

### OpenAI GPT-OSS (general-purpose text)

- `vllm-oss20b` â†’ served as **`gpt-oss-20b`**
  - **Type:** general-purpose text
  - **Best for:** everyday assistant, summarization, RAG answers, email drafting, planning
  - **Strengths:** strong quality/latency balance, reliable instruction-following
  - **Tradeoffs:** not the absolute best at deep multi-step reasoning
  - **Endpoints:**
    - âœ… `/v1/responses` *(tool use: browsing, python, MCP)*
    - âœ… `/v1/chat/completions` *(reasoning + text output)*
    - âœ… `/v1/completions` *(simple I/O)*

    **Example: Tool Use Request**
    ```bash
    curl -sS -X POST http://localhost:8009/v1/gpt-oss-20b/responses \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer ${VLLM_API_KEY}" \
      -d '{
        "model": "gpt-oss-20b",
        "input": [
          {
            "role": "user",
            "content": [
              { "type": "text", "text": "Search for latest AI news" }
            ]
          }
        ]
      }'
    ```

- `vllm-oss120b` â†’ served as **`gpt-oss-120b`**
  - **Type:** large general-purpose text
  - **Best for:** best answer quality, harder writing + synthesis, complex instruction-following
  - **Strengths:** higher ceiling than 20B for tricky prompts
  - **Tradeoffs:** slower + more expensive
  - **Endpoints:** same as `gpt-oss-20b`

### Llama 3.3 (Meta)

- `vllm-llama-3.3-70b-instruct-fp4` â†’ served as **`llama-3.3-70b-instruct-fp4`**
  - **Type:** open-weights general model (70B), NVFP4
  - **Best for:** general chat, creative writing, complex instructions
  - **Tradeoffs:** **âš ï¸ Not recommended for OpenCode** (client-side incompatibility causes aggressive tool calling errors).
  - **Note:** Works well via standard API/Curl, but open-source agents may struggle with its tool format.

### Qwen3-Next 80B-A3B (MoE efficiency)

- `vllm-qwen3-next-80b-fp4` â†’ served as **`qwen3-next-80b-a3b-instruct-fp4`**
  - **Type:** MoE (â‰ˆ80B total, ~3B active), NVFP4
  - **Best for:** fast general chat at scale, long prompts, multi-turn workflows
  - **Strengths:** excellent throughput for its â€œeffective sizeâ€
  - **Tradeoffs:** can be less careful than â€œthinkingâ€ variants on hard reasoning

- `vllm-qwen3-next-80b-thinking-fp4` â†’ served as **`qwen3-next-80b-a3b-thinking-fp4`**
  - **Type:** MoE â€œthinkingâ€/reasoning variant, NVFP4
  - **Best for:** math, logic, planning, tool-driven pipelines
  - **Strengths:** better step-by-step reliability than the instruct version
  - **Tradeoffs:** typically uses more tokens / slower per answer

### Vision-Language (VL)

- `vllm-qwen3-vl-32b-fp4` â†’ served as **`qwen3-vl-32b-instruct-fp4`**
  - **Type:** vision-language, 32B, NVFP4
  - **Best for:** screenshots, PDFs-as-images, UI understanding, diagrams
  - **Strengths:** strong doc + screenshot reasoning
  - **Tradeoffs:** heavier than 7B VL models

- `vllm-qwen3-vl-30b-thinking` â†’ served as **`qwen3-vl-30b-thinking-instruct`**
  - **Type:** vision-language "thinking" model, 30B
  - **Best for:** complex visual reasoning, step-by-step analysis of images
  - **Strengths:** enhanced reasoning capabilities over standard instruction model
  - **Tradeoffs:** slower inference due to thinking process

- `vllm-qwen25-vl-7b` â†’ served as **`qwen2.5-vl-7b`**
  - **Type:** vision-language, 7B (4-bit AWQ)
  - **Best for:** low-cost image QA, simple screenshot reading
  - **Strengths:** cheap + fast VL
  - **Tradeoffs:** weaker at dense docs / complex visuals than 32B VL

### GLM family (text + vision)

- `vllm-glm-4.5-air-fp4` â†’ served as **`glm-4.5-air-fp4`**
  - **Type:** general-purpose text, NVFP4
  - **Best for:** assistant workflows, long conversations, â€œagent-yâ€ behavior
  - **Strengths:** pragmatic instruction-following
  - **Tradeoffs:** may vary in style vs GPT/Qwen

- `vllm-glm-4.6v-flash-fp4` â†’ served as **`glm-4.6v-flash-fp4`**
  - **Type:** vision-language â€œflashâ€ (low latency), NVFP4
  - **Best for:** real-time UI agents, fast screenshot interpretation
  - **Strengths:** very fast VL
  - **Tradeoffs:** not the top choice for deep reasoning

- `vllm-glm-4.5-air-derestricted-fp4` â†’ served as **`glm-4.5-air-derestricted-fp4`**
  - **Type:** derestricted text model, NVFP4
  - **Best for:** internal testing, fewer refusals, creative/roleplay
  - **âš ï¸ Avoid for:** public/prod deployments without additional safety controls

- `vllm-glm4-9b` â†’ served as **`glm-4-9b-chat`**
  - **Type:** small chat model (~9B)
  - **Best for:** cheap chat, lightweight assistants, simple Q&A
  - **Tradeoffs:** weaker reasoning + coding than 30B+ models

### Coding specialists

- `vllm-qwen3-coder-30b` â†’ served as **`qwen3-coder-30b-a3b-instruct`**
  - **Type:** coding MoE, NVFP4
  - **Best for:** long-context coding, refactors, codebase understanding
  - **Strengths:** excellent with large context + tool loops
  - **Tradeoffs:** sometimes less â€œpolishedâ€ natural language than a general chat model

- `vllm-qwen25-coder-7b` â†’ served as **`qwen2.5-coder-7b-instruct`**
  - **Type:** small coding model
  - **Best for:** quick scripts, autocomplete, low-cost coding help
  - **Tradeoffs:** struggles with complex multi-file refactors

### Reasoning specialists

- `vllm-deepseek-r1-14b` â†’ served as **`deepseek-r1-distill-qwen-14b`**
  - **Type:** reasoning model (distilled)
  - **Best for:** reasoning on a budget, single-GPU workloads
  - **Tip:** often performs best at **temp ~0.6** for reasoning consistency

- `vllm-deepseek-r1-32b` â†’ served as **`deepseek-r1-distill-qwen-32b`**
  - **Type:** larger reasoning model (distilled)
  - **Best for:** difficult reasoning + planning, better reliability than 14B
  - **Tradeoffs:** slower/heavier than 14B

- `vllm-phi-4-reasoning-plus-fp4` â†’ served as **`phi-4-reasoning-plus-fp4`**
  - **Type:** reasoning-focused text model, NVFP4
  - **Best for:** careful multi-step analysis, complex logic, robust answers
  - **Tradeoffs:** may be slower / more verbose

- `vllm-nemotron-3-nano-30b-fp8` â†’ served as **`nemotron-3-nano-30b-fp8`**
  - **Type:** efficient MoE reasoning model, FP8
  - **Best for:** production agent workloads, long prompts, fast reasoning at scale
  - **Strengths:** strong efficiency and throughput
  - **Tradeoffs:** may be less â€œchattyâ€ than general assistants

### Multilingual / EU

- `vllm-eurollm-22b-fp4` â†’ served as **`eurollm-22b-instruct-fp4`**
  - **Type:** multilingual text model, NVFP4
  - **Best for:** EU languages, translation, multilingual RAG / customer support
  - **Strengths:** strong coverage across European languages
  - **Tradeoffs:** **Text Only** (No tool calling). **Not for OpenCode** (System prompt leakage).

### OCR

- `vllm-deepseek-ocr` â†’ served as **`deepseek-ocr`**
  - **Type:** OCR (image â†’ text)
  - **Best for:** extracting raw text from scans/screenshots
  - **Tradeoffs:** **Utility only**. Not designed for direct chat or OpenCode (use via API).
  - **Recommended pipeline:** OCR â†’ send extracted text into a reasoning/chat model

### Audio (Disabled)

- `vllm-step-audio-r1-fp4` â†’ served as **`step-audio-r1-fp4`** (Disabled)
  - **Type:** audio reasoning model, NVFP4 (custom vLLM container)
  - **Best for:** speech/audio understanding + reasoning tasks
  - **Tradeoffs:** not a general â€œbest text modelâ€ (use alongside a text model)

### Small / utility

- `vllm-qwen2.5-1.5b` â†’ served as **`qwen2.5-1.5b-instruct`**
  - **Type:** small instruction model, Qwen 2.5 (1.5B params)
  - **Best for:** labeling, routing, JSON formatting, session titles, short structured tasks
  - **Tradeoffs:** Highly efficient, but less capable for complex reasoning tasks.

### Multimodal â€œone model for everythingâ€

- `vllm-phi-4-multimodal-fp4` â†’ served as **`phi-4-multimodal-instruct-fp4`**
  - **Type:** multimodal (text + image [+audio]), NVFP4
  - **Best for:** apps that need one endpoint for mixed inputs
  - **Strengths:** strong â€œgeneral multimodal assistantâ€
  - **Tradeoffs:** may not beat best-in-class specialist models (VL-only or reasoning-only)

- `vllm-nemotron` â†’ served as **`nemotron-nano-12b-v2-vl`**
  - **Type:** smaller vision-language model
  - **Best for:** lightweight vision assistants and image Q&A
  - **Tradeoffs:** weaker than Qwen3-VL-32B on dense documents
